* Adjust gencode on CMakeLists.txt
Configure the gencode on the CMakeLists.txt
#+begin_src bash
# For hype4:
#SET(CMAKE_CUDA_FLAGS "-gencode arch=compute_37,code=sm_37")
# For tupi1:
SET(CMAKE_CUDA_FLAGS "-gencode arch=compute_61,code=sm_61")
#+end_src
* Learning from nvJPEG example 

** Initialization 

#+begin_src C++
struct decode_params_t {
  std::string input_dir;
  int batch_size;
  int total_images;
  int dev;
  int warmup;

  nvjpegJpegState_t nvjpeg_state;
  nvjpegHandle_t nvjpeg_handle;
  cudaStream_t stream;

  // used with decoupled API
  nvjpegJpegState_t nvjpeg_decoupled_state;
  nvjpegBufferPinned_t pinned_buffers[2]; // 2 buffers for pipelining
  nvjpegBufferDevice_t device_buffer;
  nvjpegJpegStream_t  jpeg_streams[2]; //  2 streams for pipelining
  nvjpegDecodeParams_t nvjpeg_decode_params;
  nvjpegJpegDecoder_t nvjpeg_decoder;

  nvjpegOutputFormat_t fmt;
  bool write_decoded;
  std::string output_dir;

  bool hw_decode_available;
};


int dev_malloc(void **p, size_t s) {
 return (int)cudaMalloc(p, s); 
}

int dev_free(void *p) { 
  return (int)cudaFree(p); 
}

int host_malloc(void** p, size_t s, unsigned int f) {
  return (int)cudaHostAlloc(p, s, f);
}

int host_free(void* p) { 
  return (int)cudaFreeHost(p); 
}

// On MAIN:

nvjpegDevAllocator_t dev_allocator = {&dev_malloc, &dev_free};
nvjpegPinnedAllocator_t pinned_allocator ={&host_malloc, &host_free};

#+end_src

** nvjpegCreateEx

#+begin_src C++

nvjpegStatus_t status = nvjpegCreateEx(
  NVJPEG_BACKEND_HARDWARE, 
  &dev_allocator,
  &pinned_allocator,
  NVJPEG_FLAGS_DEFAULT,  
  &params.nvjpeg_handle);

#+end_src

DOC: https://docs.nvidia.com/cuda/nvjpeg/index.html#nvjpeg-create-ex
Description: Allocates and initializes the library handle using the provided arguments. 

#+begin_src C++
nvjpegStatus_t nvjpegCreateEx(
          nvjpegBackend_t backend, 
          nvjpegDevAllocator_t *dev_allocator, 
          nvjpegPinnedAllocator_t *pinned_allocator, 
          unsigned int flags,
          nvjpegHandle_t *handle);
#+end_src

*** nvjpegBackend_t backend 
- https://docs.nvidia.com/cuda/nvjpeg/index.html#nvjpeg-backend

| Member                    | Description                                                                      |
|---------------------------+----------------------------------------------------------------------------------|
| NVJPEG_BACKEND_DEFAULT    | Back-end is selected internally                                                  |
| NVJPEG_BACKEND_HYBRID     | Uses CPU for Huffman decoding                                                    |
| NVJPEG_BACKEND_GPU_HYBRID | Uses GPU for Huffman decoding. GPU assisted Huffman decoding for batchsize > 100 |
| NVJPEG_BACKEND_HARDWARE   | Uses Hardware Acceleration for decode.*                                          |
|---------------------------+----------------------------------------------------------------------------------|
*Supports baseline JPEG images with single scan with 1 or 3 channels. 410 and 411 chroma subsamplings are not supported. 

*** nvjpegDevAllocator_t *dev_allocator
- Device memory allocator.

#+begin_src C++
// Allocate memory on the device. 
int dev_malloc(void **p, size_t s) {
 return (int)cudaMalloc(p, s); 
// p - Pointer to allocated device memory 
// s - Requested allocation size in bytes

}
#+end_src

*** nvjpegPinnedAllocator_t *pinned_allocator
DOC: 
Description: Pinned host memory allocator.

When the nvjpegPinnedAllocator_t *allocator parameter in the nvjpegCreateEx() function is set as a pointer to the above nvjpegPinnedAllocator_t structure, then this structure will be used for allocating and releasing host pinned memory for copying data to/from device. The function prototypes for the memory allocation and memory freeing functions are similar to the cudaHostAlloc() and cudaFreeHost() functions. They will return 0 in case of success, and non-zero otherwise.

However, if the nvjpegPinnedAllocator_t *allocator parameter in the nvjpegCreateEx() function is set to NULL, then the default memory allocation functions cudaHostAlloc() and cudaFreeHost() will be used. When using nvjpegCreate() or nvjpegCreateSimple() function to create library handle, the default host pinned memory allocator will be used. 

#+begin_src C++
// Allocates page-locked memory on the host.
//  pHost     - Device pointer to allocated memory 
//  size    - Requested allocation size in bytes 
//  flags    - Requested properties of allocated memory

int host_malloc(void** p, size_t s, unsigned int f) {
  return (int)cudaHostAlloc(p, s, f);
  
}
#+end_src

*** unsigned int flags
DOC: https://docs.nvidia.com/cuda/nvjpeg/index.html#nvjpeg-flags
| Member                                        | Description                                                       |
|-----------------------------------------------+-------------------------------------------------------------------|
| NVJPEG_FLAGS_DEFAULT                          | Corresponds to default library behavior                           |
| NVJPEG_FLAGS_HW_DECODE_NO_PIPELINE            | To be used with NVJPEG_BACKEND_HARDWARE.                          |
| NVJPEG_FLAGS_ENABLE_MEMORY_POOLS [Deprecated] | Starting with CUDA 11.1 this flag will be ignored                 |
| NVJPEG_FLAGS_BITSTREAM_STRICT                 | nvJPEG library will try to decode a bitstream not in JPEG format. |
|-----------------------------------------------+-------------------------------------------------------------------|

*** nvjpegHandle_t *handle
The library handle.
#+begin_src C++
// Can be initialize with:
nvjpegHandle_t nvjpeg_handle;
#+end_src

** nvjpegJpegStateCreate
Description: Allocates and initializes the internal structure required for the JPEG processing. 
DOC: https://docs.nvidia.com/cuda/nvjpeg/index.html#nvjpegJpegStateCreate

#+begin_src C++
nvjpegStatus_t nvjpegJpegStateCreate(
	nvjpegHandle_t      handle,
	nvjpegJpegState_t   *jpeg_handle);
#+end_src

Params: 
nvjpegHandle_t - Input - The library handle.
nvjpegJpegState_t - Input/Output - The image state handle.

Returns:
nvjpegStatus_t - An error code. One of the following:
#+begin_src C++
 NVJPEG_STATUS_SUCCESS = 0,
 NVJPEG_STATUS_NOT_INITIALIZED = 1,
 NVJPEG_STATUS_INVALID_PARAMETER = 2,
 NVJPEG_STATUS_BAD_JPEG = 3,
 NVJPEG_STATUS_JPEG_NOT_SUPPORTED = 4,
 NVJPEG_STATUS_ALLOCATOR_FAILURE = 5,
 NVJPEG_STATUS_EXECUTION_FAILED = 6,
 NVJPEG_STATUS_ARCH_MISMATCH = 7,
 NVJPEG_STATUS_INTERNAL_ERROR = 8,
 NVJPEG_STATUS_IMPLEMENTATION_NOT_SUPPORTED = 9
#+end_src

** nvjpegDecoderCreate
Description: Creates a decoder handle. 
DOC: https://docs.nvidia.com/cuda/nvjpeg/index.html#nvjpeg-decoder-create

#+begin_src C++
nvjpegStatus_t nvjpegDecoderCreate(
	nvjpegHandle_t nvjpeg_handle, 
	nvjpegBackend_t implementation, 
	nvjpegJpegDecoder_t* decoder_handle);
#+end_src

Params:

nvjpegHandle_t nvjpeg_handle - Input - Library handle.
nvjpegBackend_t backend - Input - Backend parameter for the decoder_handle.
nvjpegJpegDecoder_t decoder_handle - Input/Output - Decoder state handle.

Returns:

nvjpegStatus_t - An error code.
#+begin_src C++
NVJPEG_STATUS_SUCCESS = 0,
 NVJPEG_STATUS_NOT_INITIALIZED = 1,
 NVJPEG_STATUS_INVALID_PARAMETER = 2,
 NVJPEG_STATUS_BAD_JPEG = 3,
 NVJPEG_STATUS_JPEG_NOT_SUPPORTED = 4,
 NVJPEG_STATUS_ALLOCATOR_FAILURE = 5,
 NVJPEG_STATUS_EXECUTION_FAILED = 6,
 NVJPEG_STATUS_ARCH_MISMATCH = 7,
 NVJPEG_STATUS_INTERNAL_ERROR = 8,
 NVJPEG_STATUS_IMPLEMENTATION_NOT_SUPPORTED = 9
#+end_src

** nvjpegDecoderStateCreate
Description: Creates the decoder_state internal structure. 
The decoder_state is associated with the nvjpegBackend_t implementation that was used to create the decoder_handle. 
DOC: https://docs.nvidia.com/cuda/nvjpeg/index.html#nvjpeg-decoder-state-create

#+begin_src C++
nvjpegStatus_t nvjpegDecoderStateCreate(
	nvjpegHandle_t nvjpeg_handle,
	nvjpegJpegDecoder_t decoder_handle,
	nvjpegJpegState_t* decoder_state);
#+end_src

Params: 
nvjpegHandle_t nvjpeg_handle 	Input 	Host 	Library handle.
nvjpegJpegDecoder_t decoder_handle 	Input 	Host 	Decoder handle.
nvjpegJpegState_t* decoder_state 	Input/Output 	Host 	nvJPEG Image State Handle.

Return:
nvjpegStatus_t - An error code as specified in nvJPEG API Return Codes. 

** nvjpegBufferPinnedCreate
Creates a pinned buffer handle. 

#+begin_src C++
nvjpegStatus_t nvjpegBufferPinnedCreate(
	nvjpegHandle_t handle, 
	nvjpegPinnedAllocator_t* pinned_allocator,
	nvjpegBufferPinned_t* buffer);
#+end_src
Parameters:
Parameter 	Input / Output 	Memory 	Description
nvjpegHandle_t handle 	Input 	Host 	Library handle.
nvjpegPinnedAllocator_t* pinned_allocator 	Input 	Host 	Pinned host memory allocator. See nvjpegPinnedAllocator_t structure description.
nvjpegBufferPinned_t* buffer 	Input/Output 	Host 	nvJPEG pinned buffer object.

OBS: However, if the nvjpegPinnedAllocator_t *allocator parameter in the
nvjpegCreateEx() function is set to NULL, then the default memory allocation
functions cudaHostAlloc() and cudaFreeHost() will be used 

Returns:
nvjpegStatus_t - An error code as specified in nvJPEG API Return Codes. 

** nvjpegBufferDeviceCreate
Creates the device buffer handle. 
Signature:

#+begin_src C++
nvjpegStatus_t nvjpegBufferDeviceCreate(
	nvjpegHandle_t handle, 
	nvjpegDevAllocator_t* device_allocator,
	nvjpegBufferDevice_t* buffer);
#+end_src

Parameters:
Parameter 	Input / Output 	Memory 	Description
nvjpegHandle_t handle 	Input 	Host 	Library handle.
nvjpegDevAllocator_t* device_allocator 	Input 	Host 	Device memory allocator. See nvjpegDevAllocator_t structure description.
nvjpegBufferDevice_t* buffer 	Input/Output 	Host 	nvJPEG device buffer container.

Returns:

nvjpegStatus_t - An error code as specified in nvJPEG API Return Codes. 
** nvjpegJpegStreamCreate
Creates jpeg_stream that is used to parse the JPEG bitstream and store bitstream parameters.

Signature:

#+begin_src C++
nvjpegStatus_t nvjpegJpegStreamCreate(
	nvjpegHandle_t handle, 
	nvjpegJpegStream_t *jpeg_stream);
#+end_src	

Parameters:
Parameter 	Input / Output 	Memory 	Description
nvjpegHandle_t handle 	Input 	Host 	Library handle
nvjpegJpegStream_t *jpeg_stream 	Input 	Host 	Bitstream handle

Returns:

nvjpegStatus_t - An error code as specified in nvJPEG API Return Codes.

** nvjpegDecodeParamsCreate
Creates a handle for the parameters. 
The parameters that can be programmed include: output format, ROI decode, CMYK to RGB conversion.

Signature:

#+begin_src C++
nvjpegStatus_t nvjpegDecodeParamsCreate(
	nvjpegHandle_t handle, 
	nvjpegDecodeParams_t *decode_params);
#+end_src

Parameters:
Parameter 	Input / Output 	Memory 	Description
nvjpegHandle_t handle 	Input 	Host 	Library handle.
nvjpegDecodeParams_t *decode_params 	Input/Output 	Host 	Decode output parameters.

Returns:

nvjpegStatus_t - An error code as specified in nvJPEG API Return Codes. 

* CPU performance test
** Run test
#+begin_src R :results output :exports both :session *R*
  library(tidyverse)

  machine <- "tupi1"
  cpu_bin <- "/home/users/bsalves/pheno-on-GPU/CPU-decode/cpu-decode"
  images_path <- "/tmp/ePhenology_phenocam_CORE_2011-2020/"

  tibble(
    run.n_images = seq(0, 1500, 100),
    machine = machine,
    cpu_bin = cpu_bin,
    images_path = images_path
  ) %>%
    mutate(run.n_images = if_else(run.n_images == 0, 1, run.n_images)) %>%
    mutate(cmd = paste(cpu_bin, images_path, run.n_images, sep=" ")) %>%
    rowwise() %>%
    mutate(run.output = system(cmd, intern=TRUE)) %>%
    mutate(run.output.split = strsplit(run.output, ", ")) %>%
    mutate(
      decode_time = as.double(run.output.split[1]),
      calc_time = as.double(run.output.split[2]),
      decode_time.by_image = as.double(run.output.split[3]),
      calc_time.by_image = as.double(run.output.split[4]),
    ) %>%
    select(-run.output.split) %>%
    select(machine, run.n_images, contains("time")) %>%
    print -> cpu_performance

cpu_performance %>%
  write_csv(paste0("CPU_", machine, ".csv"))
      #select(contains("time")) 
#+end_src

#+RESULTS:
#+begin_example
â”€â”€ Attaching packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 1.3.0 â”€â”€
âœ” ggplot2 3.3.3     âœ” purrr   0.3.4
âœ” tibble  3.1.0     âœ” dplyr   1.0.5
âœ” tidyr   1.1.3     âœ” stringr 1.4.0
âœ” readr   1.4.0     âœ” forcats 0.5.1
â”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€
âœ– dplyr::filter() masks stats::filter()
âœ– dplyr::lag()    masks stats::lag()
# A tibble: 16 x 6
# Rowwise: 
   machine run.n_images decode_time calc_time decode_time.by_iâ€¦ calc_time.by_imâ€¦
   <
         <
      <
    <
            <
           <dbl>
 1 tupi1              1        7970      1366             7970             1366 
 2 tupi1            100      683238    148402             6832.            1484.
 3 tupi1            200     1362524    274073             6813.            1370.
 4 tupi1            300     2045802    410613             6819.            1369.
 5 tupi1            400     2725708    552691             6814.            1382.
 6 tupi1            500     3405040    684818             6810.            1370.
 7 tupi1            600     4097587    825258             6829.            1375.
 8 tupi1            700     4885334    958098             6979.            1369.
 9 tupi1            800     5725981   1097219             7157.            1372.
10 tupi1            900     6556419   1230293             7285.            1367.
11 tupi1           1000     7392242   1368887             7392.            1369.
12 tupi1           1100     8225203   1506520             7477.            1370.
13 tupi1           1200     9095637   1647165             7580.            1373.
14 tupi1           1300     9999201   1779472             7692.            1369.
15 tupi1           1400    10890980   1912277             7779.            1366.
16 tupi1           1500    11792037   2051870             7861.            1368.
#+end_example
** CPU times plot
#+begin_src R :results output :exports both :session *R-local*
library(tidyverse)
system("scp parque:/home/users/bsalves/CPU_tupi1.csv .")

#+end_src

#+RESULTS:
: â”€â”€ [1mAttaching packages[22m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 1.3.1 â”€â”€
: [32mâœ”[39m [34mggplot2[39m 3.3.5     [32mâœ”[39m [34mpurrr  [39m 0.3.4
: [32mâœ”[39m [34mtibble [39m 3.1.3     [32mâœ”[39m [34mdplyr  [39m 1.0.7
: [32mâœ”[39m [34mtidyr  [39m 1.1.3     [32mâœ”[39m [34mstringr[39m 1.4.0
: [32mâœ”[39m [34mreadr  [39m 2.0.1     [32mâœ”[39m [34mforcats[39m 0.5.1
: â”€â”€ [1mConflicts[22m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€
: [31mâœ–[39m [34mdplyr[39m::[32mfilter()[39m masks [34mstats[39m::filter()
: [31mâœ–[39m [34mdplyr[39m::[32mlag()[39m    masks [34mstats[39m::lag()
: CPU_tupi1.csv                                     0%    0     0.0KB/s   --:-- ETACPU_tupi1.csv                                   100%  802    69.4KB/s   00:00


#+begin_src R :results output file graphics :file (concat "~/R-images/image-" (replace-regexp-in-string " " "_" (nth 4 (org-heading-components))) ".png") :exports both :width 600 :height 400 :session *R-local*

read_csv("CPU_tupi1.csv") %>%
  as_tibble() %>%
#  mutate() %>%
  ggplot() +
  geom_line(aes(x=run.n_images, y=decode_time), color="black") + 
  geom_line(aes(x=run.n_images, y=calc_time), color="black")
#+end_src

#+RESULTS:
[[file:~/R-images/image-CPU_times_plot.png]]


* GPU performance test
** Build program
#+begin_src bash
cd GPU-decode
mkdir build; cd build; cmake ..; make; cd ..
# To run
./build/nvjpegDecoder <images_path> <batch_size> <total_images_to_decode>
#+end_src
** Run test
#+begin_src R :results output :exports both :session *R*
 library(tidyverse)

  machine <- "tupi1"
  gpu_bin <- "/home/users/bsalves/pheno-on-GPU/GPU-decode/build/nvjpegDecoder"
  images_path <- "/tmp/ePhenology_phenocam_CORE_2011-2020/"

  tibble(
    run.n_images = seq(0, 1500, 100),
    machine = machine,
    gpu_bin = gpu_bin,
    images_path = images_path
  ) %>%
    mutate(run.n_images = if_else(run.n_images == 0, 1, run.n_images)) %>%
    mutate(cmd = paste(gpu_bin, images_path, 1, run.n_images, sep=" ")) %>%
    rowwise() %>%
    mutate(run.output = system(cmd, intern=TRUE)) %>%
    mutate(run.output.split = strsplit(run.output, ", ")) %>%
    mutate(
      fread_time = as.double(run.output.split[1]),
      decode_time = as.double(run.output.split[2]),
      calc_time = as.double(run.output.split[3]),
      fread_time.by_image = as.double(run.output.split[4]),
      decode_time.by_image = as.double(run.output.split[5]),
      calc_time.by_image = as.double(run.output.split[6])
    ) %>%
    select(-run.output.split) %>%
    select(machine, run.n_images, contains("time")) %>%
    print -> cpu_performance

cpu_performance %>%
  write_csv(paste0("GPU_", machine, ".csv"))
      #select(contains("time")) 

#+end_src

#+RESULTS:
#+begin_example
# A tibble: 16 x 8
# Rowwise: 
   machine run.n_images fread_time decode_time calc_time fread_time.by_image
   <
         <
     <
      <
    <
              <dbl>
 1 tupi1              1        172        6223       126                172 
 2 tupi1            100      12278      407530      8258                123.
 3 tupi1            200      24695      815761     16246                123.
 4 tupi1            300      36363     1225981     24962                121.
 5 tupi1            400      48458     1635388     31863                121.
 6 tupi1            500      61201     2038722     43073                122.
 7 tupi1            600      73775     2453825     50784                123.
 8 tupi1            700      92051     2995278     55481                132.
 9 tupi1            800     109807     3563208     64460                137.
10 tupi1            900     128879     4148277     70846                143.
11 tupi1           1000     147974     4730452     78300                148.
12 tupi1           1100     165516     5345620     86829                150.
13 tupi1           1200     187570     5899312     92268                156.
14 tupi1           1300     210559     6561272    100702                162.
15 tupi1           1400     232551     7220194    115195                166.
16 tupi1           1500     256486     7867113    124968                171.
# â€¦ with 2 more variables: decode_time.by_image <dbl>, calc_time.by_image <dbl>
#+end_example

** GPU times plot
#+begin_src R :results output :exports both :session *R-local*
library(tidyverse)
options(crayon.enabled = FALSE)
system("scp parque:/home/users/bsalves/GPU_tupi1.csv .")

#+end_src

#+RESULTS:
: GPU_tupi1.csv                                     0%    0     0.0KB/s   --:-- ETAGPU_tupi1.csv                                   100% 1029    82.2KB/s   00:00


#+begin_src R :results output file graphics :file (concat "~/R-images/image-" (replace-regexp-in-string " " "_" (nth 4 (org-heading-components))) ".png") :exports both :width 600 :height 400 :session *R-local*

read_csv("GPU_tupi1.csv") %>%
  as_tibble() %>%
#  mutate() %>%
  ggplot() +
  geom_line(aes(x=run.n_images, y=decode_time), color="black") + 
  geom_line(aes(x=run.n_images, y=calc_time), color="black")
#+end_src

#+RESULTS:
[[file:~/R-images/image-GPU_times_plot.png]]


* CPU x GPU 

#+begin_src R :results output :exports both :session *R-local*
read_csv("GPU_tupi1.csv") %>%
  as_tibble() -> df.gpu

read_csv("CPU_tupi1.csv") %>%
  as_tibble() -> df.cpu

#+end_src

#+RESULTS:
#+begin_example
indexing GPU_tupi1.csv [==================================] 126.94MB/s, eta:  0s                                                                                Rows: 16 Columns: 8
â”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Delimiter: ","
chr (1): machine
dbl (7): run.n_images, fread_time, decode_time, calc_time, fread_time.by_ima...

â„¹ Use `spec()` to retrieve the full column specification for this data.
â„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
indexing CPU_tupi1.csv [==================================] 101.93MB/s, eta:  0s                                                                                Rows: 16 Columns: 6
â”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Delimiter: ","
chr (1): machine
dbl (5): run.n_images, decode_time, calc_time, decode_time.by_image, calc_ti...

â„¹ Use `spec()` to retrieve the full column specification for this data.
â„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
#+end_example


#+begin_src R :results output file graphics :file (concat "~/R-images/image-" (replace-regexp-in-string " " "_" (nth 4 (org-heading-components))) ".png") :exports both :width 800 :height 400 :session *R-local*
library(patchwork)
 
bind_rows(
  df.gpu %>%
#    select(-contains("by_image")) %>%
    select(-contains(".by_image")) %>%
    mutate(decode_time = decode_time + fread_time) %>%
    select(-fread_time) %>%
    mutate(type = "GPU - batch = 1") %>%
    pivot_longer(
        cols = contains("time"),
        names_to = "operation",
        values_to = "time"
    ), 
  df.cpu %>%
    mutate(type = "CPU - 1 core") %>%
    select(-contains(".by_image")) %>%
    pivot_longer(
        cols = contains("time"),
        names_to = "operation",
        values_to = "time"
    )
) %>%
  mutate(Type = paste(type, operation, sep=" -- ")) %>%
  ggplot() +
  geom_point(aes(x=run.n_images, y=time, colour=type)) + 
  geom_line(aes(x=run.n_images, y=time, colour=type)) + 
  theme_bw(base_size=16) +
  facet_wrap(~operation,scales = "free") +
  xlab("Number of images") + 
  ylab("Time in microseconds")

#+end_src

#+RESULTS:
[[file:~/R-images/image-CPU_x_GPU.png]]

